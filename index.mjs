import fs from 'fs/promises';

const OCR_PROMPT = "YYou are a CAPTCHA testing engine tasked with ensuring the accuracy and security of CAPTCHA codes. Your responsibility is to identify the text within images, providing the most probable result with maximum effort. Return only the text, ensuring it is clean and contains only English letters and numbers, devoid of extra spaces or symbols. The scope you need to identify should include all uppercase English letters and numbers. No other characters will appear. The returned string length should be between 4 and 6 characters. Note that the CAPTCHA has a strong anti-bot design. You should make every effort to analyze and simulate human visual perception to identify the most likely result, instead of simply using OCR to recognize all characters. The actual characters should be relatively complete and occupy a larger proportion of the image. Tiny text should not be part of the result but rather a distraction design. You need to simulate the characteristics of how the human eye perceives images for acute analysis. Return the three most probable and distinct results, ranked by likelihood. Output a JSON object with a property 'results' array containing the identified characters results. Example: {\"results\": [\"ABCD\", \"ABCE\", \"ABCF\"]}";

const JUDGE_PROMPT = `You are an expert CAPTCHA Judge.You will be provided with a CAPTCHA image and a list of potential readings generated by multiple OCR models.Your task is to analyze the image visualy and evaluate the candidates to determine the correct text.

candidates:

\$\{CANDIDATES\}

The models rank results by likelihood based on their individual estimations. The challenge is to infer the most probable outcome, considering that the top-ranked result or the most frequent prediction may not be correct. A component and feature-based analysis, potentially referencing the images again, may be necessary for the final judgment.

Output a JSON object with a property 'final_text' containing the single best result. Example: {\"final_text\": \"UE5K\"}`;

class VllmOcr {
    constructor(config = {}) {
        this.apiKey = config.apiKey || process.env.OPENROUTER_API_KEY;
        this.models = config.models || [
            'google/gemini-3-pro-preview',
            'openai/gpt-5.1',
            'qwen/qwen3-vl-235b-a22b-thinking',
        ];
        this.judgeModel = config.judgeModel || 'openai/gpt-5.1';
        this.baseUrl = config.baseUrl || 'https://openrouter.ai/api/v1';
        this.siteUrl = config.siteUrl || 'https://github.com/leask/decaptcha';
        this.appName = config.appName || 'Decaptcha';
        // fastMode is no longer relevant for the OCR phase as we need all results for the Judge

        if (!this.apiKey) {
            throw new Error('OpenRouter API Key is required.');
        }
    }

    async recognize(imagePathOrBuffer) {
        let base64Image;
        let mimeType;

        if (Buffer.isBuffer(imagePathOrBuffer)) {
            base64Image = imagePathOrBuffer.toString('base64');
            mimeType = 'image/jpeg';
        } else if (typeof imagePathOrBuffer === 'string') {
            const buffer = await fs.readFile(imagePathOrBuffer);
            base64Image = buffer.toString('base64');
            mimeType = imagePathOrBuffer.toLowerCase().endsWith('.png') ? 'image/png' : 'image/jpeg';
        } else {
            throw new Error('Invalid input. Expected file path string or Buffer.');
        }

        // 1. Collect results from all worker models
        const promises = this.models.map(model =>
            this._callOpenRouter(model, OCR_PROMPT, base64Image, mimeType)
                .then(result => ({ model, ...result }))
                .catch(err => ({ model, error: err.message, candidates: [] }))
        );

        const results = await Promise.all(promises);

        // 2. Send results to the Judge
        const finalResult = await this._judge(base64Image, mimeType, results);

        return {
            final_text: finalResult,
            details: this._sortResultsByModelOrder(results)
        };
    }

    async _judge(base64Image, mimeType, results) {
        // Format candidates for the prompt
        // We aggregate all unique candidates to keep the prompt clean,
        // or we can list them by model to give context (e.g. "GPT-5 thinks X").
        // Listing by model might help the Judge weigh reliable models implicitly.

        let candidatesDescription = "";
        const allCandidates = new Set();

        results.forEach(r => {
            if (r.candidates && r.candidates.length > 0) {
                const modelName = r.model.split('/').pop();
                candidatesDescription += `- ${modelName}: [${r.candidates.join(', ')}]
`;
                r.candidates.forEach(c => allCandidates.add(c));
            }
        });

        if (allCandidates.size === 0) {
            return null; // No candidates to judge
        }

        const prompt = JUDGE_PROMPT.replace('${CANDIDATES}', candidatesDescription);

        // console.log(prompt);

        try {
            const result = await this._callOpenRouter(this.judgeModel, prompt, base64Image, mimeType);

            // The judge returns { candidates: [...] } because _callOpenRouter parses 'results' or 'text'.
            // Our prompt asks for 'final_text', which _callOpenRouter handles via fallback to 'text' parsing.
            // But _callOpenRouter expects 'results' array or 'text'.
            // Let's ensure _callOpenRouter can handle the Judge's simple JSON response.

            if (result.candidates && result.candidates.length > 0) {
                return result.candidates[0];
            }
            return null;

        } catch (e) {
            console.error('Judge failed:', e.message);
            // Fallback: simple majority vote from the candidates if judge fails
            return this._simpleVoteFallback(results);
        }
    }

    _simpleVoteFallback(results) {
        const counts = {};
        for (const r of results) {
            if (r.candidates) {
                r.candidates.forEach(c => counts[c] = (counts[c] || 0) + 1);
            }
        }
        const sorted = Object.entries(counts).sort((a, b) => b[1] - a[1]);
        return sorted.length > 0 ? sorted[0][0] : null;
    }

    _sortResultsByModelOrder(results) {
        return results.sort((a, b) => {
            return this.models.indexOf(a.model) - this.models.indexOf(b.model);
        });
    }

    async _callOpenRouter(model, prompt, base64Image, mimeType, signal = null) {
        const url = `${this.baseUrl}/chat/completions`;
        const start = Date.now();

        const payload = {
            model: model,
            messages: [
                {
                    role: "system",
                    content: prompt,
                },
                {
                    role: "user",
                    content: [
                        { type: "text", text: "Please analyze the image and provide the output." },
                        {
                            type: "image_url",
                            image_url: {
                                url: `data:${mimeType};base64,${base64Image}`
                            }
                        }
                    ]
                }
            ],
            response_format: { type: "json_object" },
        };

        try {
            const response = await fetch(url, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${this.apiKey}`,
                    'HTTP-Referer': this.siteUrl,
                    'X-Title': this.appName,
                },
                body: JSON.stringify(payload),
                signal: signal
            });

            if (!response.ok) {
                const errorText = await response.text();
                throw new Error(`API Error: ${response.status} - ${errorText}`);
            }

            const data = await response.json();
            const duration = Date.now() - start;

            let candidates = [];
            try {
                const content = data.choices[0].message.content;

                let jsonString = content;
                const codeBlockMatch = content.match(/```(?:json)?\s*([\s\S]*?)\s*```/i);
                if (codeBlockMatch) jsonString = codeBlockMatch[1];

                const startIndex = jsonString.indexOf('{');
                const endIndex = jsonString.lastIndexOf('}');
                if (startIndex !== -1 && endIndex !== -1 && endIndex > startIndex) {
                    jsonString = jsonString.substring(startIndex, endIndex + 1);
                }

                const parsed = JSON.parse(jsonString);

                // Handle various JSON shapes
                if (Array.isArray(parsed.results)) {
                    candidates = parsed.results.map(t => this._postProcess(t)).filter(t => t);
                } else if (parsed.final_text) {
                    // Handle Judge Output
                    const processed = this._postProcess(parsed.final_text);
                    if (processed) candidates = [processed];
                } else if (parsed.text) {
                    const processed = this._postProcess(parsed.text);
                    if (processed) candidates = [processed];
                }

            } catch (e) {
                throw new Error(`Failed to parse JSON response: ${e.message}`);
            }

            if (candidates.length === 0) {
                throw new Error('JSON response missing expected fields (results, final_text, or text)');
            }

            return {
                candidates: candidates,
                duration
            };

        } catch (error) {
            return {
                candidates: [],
                error: error.message,
                duration: Date.now() - start
            };
        }
    }

    _postProcess(text) {
        if (!text) return '';
        return text.toUpperCase().replace(/[^A-Z0-9]/g, '');
    }
}

export default VllmOcr;
